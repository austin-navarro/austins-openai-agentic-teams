[Skip to content](https://openai.github.io/openai-agents-python/ref/voice/result/#result)

# `Result`

### StreamedAudioResult

The output of a `VoicePipeline`. Streams events and audio data as they're generated.

Source code in `src/agents/voice/result.py`

|     |     |
| --- | --- |
| ```<br> 28<br> 29<br> 30<br> 31<br> 32<br> 33<br> 34<br> 35<br> 36<br> 37<br> 38<br> 39<br> 40<br> 41<br> 42<br> 43<br> 44<br> 45<br> 46<br> 47<br> 48<br> 49<br> 50<br> 51<br> 52<br> 53<br> 54<br> 55<br> 56<br> 57<br> 58<br> 59<br> 60<br> 61<br> 62<br> 63<br> 64<br> 65<br> 66<br> 67<br> 68<br> 69<br> 70<br> 71<br> 72<br> 73<br> 74<br> 75<br> 76<br> 77<br> 78<br> 79<br> 80<br> 81<br> 82<br> 83<br> 84<br> 85<br> 86<br> 87<br> 88<br> 89<br> 90<br> 91<br> 92<br> 93<br> 94<br> 95<br> 96<br> 97<br> 98<br> 99<br>100<br>101<br>102<br>103<br>104<br>105<br>106<br>107<br>108<br>109<br>110<br>111<br>112<br>113<br>114<br>115<br>116<br>117<br>118<br>119<br>120<br>121<br>122<br>123<br>124<br>125<br>126<br>127<br>128<br>129<br>130<br>131<br>132<br>133<br>134<br>135<br>136<br>137<br>138<br>139<br>140<br>141<br>142<br>143<br>144<br>145<br>146<br>147<br>148<br>149<br>150<br>151<br>152<br>153<br>154<br>155<br>156<br>157<br>158<br>159<br>160<br>161<br>162<br>163<br>164<br>165<br>166<br>167<br>168<br>169<br>170<br>171<br>172<br>173<br>174<br>175<br>176<br>177<br>178<br>179<br>180<br>181<br>182<br>183<br>184<br>185<br>186<br>187<br>188<br>189<br>190<br>191<br>192<br>193<br>194<br>195<br>196<br>197<br>198<br>199<br>200<br>201<br>202<br>203<br>204<br>205<br>206<br>207<br>208<br>209<br>210<br>211<br>212<br>213<br>214<br>215<br>216<br>217<br>218<br>219<br>220<br>221<br>222<br>223<br>224<br>225<br>226<br>227<br>228<br>229<br>230<br>231<br>232<br>233<br>234<br>235<br>236<br>237<br>238<br>239<br>240<br>241<br>242<br>243<br>244<br>245<br>246<br>247<br>248<br>249<br>250<br>251<br>252<br>253<br>254<br>255<br>256<br>257<br>258<br>259<br>260<br>261<br>262<br>263<br>264<br>265<br>266<br>267<br>268<br>269<br>270<br>271<br>272<br>273<br>274<br>275<br>276<br>277<br>278<br>279<br>280<br>281<br>282<br>283<br>284<br>285<br>286<br>287<br>``` | ```md-code__content<br>class StreamedAudioResult:<br>    """The output of a `VoicePipeline`. Streams events and audio data as they're generated."""<br>    def __init__(<br>        self,<br>        tts_model: TTSModel,<br>        tts_settings: TTSModelSettings,<br>        voice_pipeline_config: VoicePipelineConfig,<br>    ):<br>        """Create a new `StreamedAudioResult` instance.<br>        Args:<br>            tts_model: The TTS model to use.<br>            tts_settings: The TTS settings to use.<br>            voice_pipeline_config: The voice pipeline config to use.<br>        """<br>        self.tts_model = tts_model<br>        self.tts_settings = tts_settings<br>        self.total_output_text = ""<br>        self.instructions = tts_settings.instructions<br>        self.text_generation_task: asyncio.Task[Any] | None = None<br>        self._voice_pipeline_config = voice_pipeline_config<br>        self._text_buffer = ""<br>        self._turn_text_buffer = ""<br>        self._queue: asyncio.Queue[VoiceStreamEvent] = asyncio.Queue()<br>        self._tasks: list[asyncio.Task[Any]] = []<br>        self._ordered_tasks: list[<br>            asyncio.Queue[VoiceStreamEvent | None]<br>        ] = []  # New: list to hold local queues for each text segment<br>        self._dispatcher_task: asyncio.Task[Any] | None = (<br>            None  # Task to dispatch audio chunks in order<br>        )<br>        self._done_processing = False<br>        self._buffer_size = tts_settings.buffer_size<br>        self._started_processing_turn = False<br>        self._first_byte_received = False<br>        self._generation_start_time: str | None = None<br>        self._completed_session = False<br>        self._stored_exception: BaseException | None = None<br>        self._tracing_span: Span[SpeechGroupSpanData] | None = None<br>    async def _start_turn(self):<br>        if self._started_processing_turn:<br>            return<br>        self._tracing_span = speech_group_span()<br>        self._tracing_span.start()<br>        self._started_processing_turn = True<br>        self._first_byte_received = False<br>        self._generation_start_time = time_iso()<br>        await self._queue.put(VoiceStreamEventLifecycle(event="turn_started"))<br>    def _set_task(self, task: asyncio.Task[Any]):<br>        self.text_generation_task = task<br>    async def _add_error(self, error: Exception):<br>        await self._queue.put(VoiceStreamEventError(error))<br>    def _transform_audio_buffer(<br>        self, buffer: list[bytes], output_dtype: npt.DTypeLike<br>    ) -> npt.NDArray[np.int16 | np.float32]:<br>        np_array = np.frombuffer(b"".join(buffer), dtype=np.int16)<br>        if output_dtype == np.int16:<br>            return np_array<br>        elif output_dtype == np.float32:<br>            return (np_array.astype(np.float32) / 32767.0).reshape(-1, 1)<br>        else:<br>            raise UserError("Invalid output dtype")<br>    async def _stream_audio(<br>        self,<br>        text: str,<br>        local_queue: asyncio.Queue[VoiceStreamEvent | None],<br>        finish_turn: bool = False,<br>    ):<br>        with speech_span(<br>            model=self.tts_model.model_name,<br>            input=text if self._voice_pipeline_config.trace_include_sensitive_data else "",<br>            model_config={<br>                "voice": self.tts_settings.voice,<br>                "instructions": self.instructions,<br>                "speed": self.tts_settings.speed,<br>            },<br>            output_format="pcm",<br>            parent=self._tracing_span,<br>        ) as tts_span:<br>            try:<br>                first_byte_received = False<br>                buffer: list[bytes] = []<br>                full_audio_data: list[bytes] = []<br>                async for chunk in self.tts_model.run(text, self.tts_settings):<br>                    if not first_byte_received:<br>                        first_byte_received = True<br>                        tts_span.span_data.first_content_at = time_iso()<br>                    if chunk:<br>                        buffer.append(chunk)<br>                        full_audio_data.append(chunk)<br>                        if len(buffer) >= self._buffer_size:<br>                            audio_np = self._transform_audio_buffer(buffer, self.tts_settings.dtype)<br>                            if self.tts_settings.transform_data:<br>                                audio_np = self.tts_settings.transform_data(audio_np)<br>                            await local_queue.put(<br>                                VoiceStreamEventAudio(data=audio_np)<br>                            )  # Use local queue<br>                            buffer = []<br>                if buffer:<br>                    audio_np = self._transform_audio_buffer(buffer, self.tts_settings.dtype)<br>                    if self.tts_settings.transform_data:<br>                        audio_np = self.tts_settings.transform_data(audio_np)<br>                    await local_queue.put(VoiceStreamEventAudio(data=audio_np))  # Use local queue<br>                if self._voice_pipeline_config.trace_include_sensitive_audio_data:<br>                    tts_span.span_data.output = _audio_to_base64(full_audio_data)<br>                else:<br>                    tts_span.span_data.output = ""<br>                if finish_turn:<br>                    await local_queue.put(VoiceStreamEventLifecycle(event="turn_ended"))<br>                else:<br>                    await local_queue.put(None)  # Signal completion for this segment<br>            except Exception as e:<br>                tts_span.set_error(<br>                    {<br>                        "message": str(e),<br>                        "data": {<br>                            "text": text<br>                            if self._voice_pipeline_config.trace_include_sensitive_data<br>                            else "",<br>                        },<br>                    }<br>                )<br>                logger.error(f"Error streaming audio: {e}")<br>                # Signal completion for whole session because of error<br>                await local_queue.put(VoiceStreamEventLifecycle(event="session_ended"))<br>                raise e<br>    async def _add_text(self, text: str):<br>        await self._start_turn()<br>        self._text_buffer += text<br>        self.total_output_text += text<br>        self._turn_text_buffer += text<br>        combined_sentences, self._text_buffer = self.tts_settings.text_splitter(self._text_buffer)<br>        if len(combined_sentences) >= 20:<br>            local_queue: asyncio.Queue[VoiceStreamEvent | None] = asyncio.Queue()<br>            self._ordered_tasks.append(local_queue)<br>            self._tasks.append(<br>                asyncio.create_task(self._stream_audio(combined_sentences, local_queue))<br>            )<br>            if self._dispatcher_task is None:<br>                self._dispatcher_task = asyncio.create_task(self._dispatch_audio())<br>    async def _turn_done(self):<br>        if self._text_buffer:<br>            local_queue: asyncio.Queue[VoiceStreamEvent | None] = asyncio.Queue()<br>            self._ordered_tasks.append(local_queue)  # Append the local queue for the final segment<br>            self._tasks.append(<br>                asyncio.create_task(<br>                    self._stream_audio(self._text_buffer, local_queue, finish_turn=True)<br>                )<br>            )<br>            self._text_buffer = ""<br>        self._done_processing = True<br>        if self._dispatcher_task is None:<br>            self._dispatcher_task = asyncio.create_task(self._dispatch_audio())<br>        await asyncio.gather(*self._tasks)<br>    def _finish_turn(self):<br>        if self._tracing_span:<br>            if self._voice_pipeline_config.trace_include_sensitive_data:<br>                self._tracing_span.span_data.input = self._turn_text_buffer<br>            else:<br>                self._tracing_span.span_data.input = ""<br>            self._tracing_span.finish()<br>            self._tracing_span = None<br>        self._turn_text_buffer = ""<br>        self._started_processing_turn = False<br>    async def _done(self):<br>        self._completed_session = True<br>        await self._wait_for_completion()<br>    async def _dispatch_audio(self):<br>        # Dispatch audio chunks from each segment in the order they were added<br>        while True:<br>            if len(self._ordered_tasks) == 0:<br>                if self._completed_session:<br>                    break<br>                await asyncio.sleep(0)<br>                continue<br>            local_queue = self._ordered_tasks.pop(0)<br>            while True:<br>                chunk = await local_queue.get()<br>                if chunk is None:<br>                    break<br>                await self._queue.put(chunk)<br>                if isinstance(chunk, VoiceStreamEventLifecycle):<br>                    local_queue.task_done()<br>                    if chunk.event == "turn_ended":<br>                        self._finish_turn()<br>                        break<br>        await self._queue.put(VoiceStreamEventLifecycle(event="session_ended"))<br>    async def _wait_for_completion(self):<br>        tasks: list[asyncio.Task[Any]] = self._tasks<br>        if self._dispatcher_task is not None:<br>            tasks.append(self._dispatcher_task)<br>        await asyncio.gather(*tasks)<br>    def _cleanup_tasks(self):<br>        self._finish_turn()<br>        for task in self._tasks:<br>            if not task.done():<br>                task.cancel()<br>        if self._dispatcher_task and not self._dispatcher_task.done():<br>            self._dispatcher_task.cancel()<br>        if self.text_generation_task and not self.text_generation_task.done():<br>            self.text_generation_task.cancel()<br>    def _check_errors(self):<br>        for task in self._tasks:<br>            if task.done():<br>                if task.exception():<br>                    self._stored_exception = task.exception()<br>                    break<br>    async def stream(self) -> AsyncIterator[VoiceStreamEvent]:<br>        """Stream the events and audio data as they're generated."""<br>        while True:<br>            try:<br>                event = await self._queue.get()<br>            except asyncio.CancelledError:<br>                break<br>            if isinstance(event, VoiceStreamEventError):<br>                self._stored_exception = event.error<br>                logger.error(f"Error processing output: {event.error}")<br>                break<br>            if event is None:<br>                break<br>            yield event<br>            if event.type == "voice_stream_event_lifecycle" and event.event == "session_ended":<br>                break<br>        self._check_errors()<br>        self._cleanup_tasks()<br>        if self._stored_exception:<br>            raise self._stored_exception<br>``` |

#### \_\_init\_\_

```md-code__content
__init__(
    tts_model: TTSModel,
    tts_settings: TTSModelSettings,
    voice_pipeline_config: VoicePipelineConfig,
)

```

Create a new `StreamedAudioResult` instance.

Parameters:

| Name | Type | Description | Default |
| --- | --- | --- | --- |
| `tts_model` | `TTSModel` | The TTS model to use. | _required_ |
| `tts_settings` | `TTSModelSettings` | The TTS settings to use. | _required_ |
| `voice_pipeline_config` | `VoicePipelineConfig` | The voice pipeline config to use. | _required_ |

Source code in `src/agents/voice/result.py`

|     |     |
| --- | --- |
| ```<br>31<br>32<br>33<br>34<br>35<br>36<br>37<br>38<br>39<br>40<br>41<br>42<br>43<br>44<br>45<br>46<br>47<br>48<br>49<br>50<br>51<br>52<br>53<br>54<br>55<br>56<br>57<br>58<br>59<br>60<br>61<br>62<br>63<br>64<br>65<br>66<br>67<br>68<br>69<br>``` | ```md-code__content<br>def __init__(<br>    self,<br>    tts_model: TTSModel,<br>    tts_settings: TTSModelSettings,<br>    voice_pipeline_config: VoicePipelineConfig,<br>):<br>    """Create a new `StreamedAudioResult` instance.<br>    Args:<br>        tts_model: The TTS model to use.<br>        tts_settings: The TTS settings to use.<br>        voice_pipeline_config: The voice pipeline config to use.<br>    """<br>    self.tts_model = tts_model<br>    self.tts_settings = tts_settings<br>    self.total_output_text = ""<br>    self.instructions = tts_settings.instructions<br>    self.text_generation_task: asyncio.Task[Any] | None = None<br>    self._voice_pipeline_config = voice_pipeline_config<br>    self._text_buffer = ""<br>    self._turn_text_buffer = ""<br>    self._queue: asyncio.Queue[VoiceStreamEvent] = asyncio.Queue()<br>    self._tasks: list[asyncio.Task[Any]] = []<br>    self._ordered_tasks: list[<br>        asyncio.Queue[VoiceStreamEvent | None]<br>    ] = []  # New: list to hold local queues for each text segment<br>    self._dispatcher_task: asyncio.Task[Any] | None = (<br>        None  # Task to dispatch audio chunks in order<br>    )<br>    self._done_processing = False<br>    self._buffer_size = tts_settings.buffer_size<br>    self._started_processing_turn = False<br>    self._first_byte_received = False<br>    self._generation_start_time: str | None = None<br>    self._completed_session = False<br>    self._stored_exception: BaseException | None = None<br>    self._tracing_span: Span[SpeechGroupSpanData] | None = None<br>``` |

#### stream`async`

```md-code__content
stream() -> AsyncIterator[VoiceStreamEvent]

```

Stream the events and audio data as they're generated.

Source code in `src/agents/voice/result.py`

|     |     |
| --- | --- |
| ```<br>266<br>267<br>268<br>269<br>270<br>271<br>272<br>273<br>274<br>275<br>276<br>277<br>278<br>279<br>280<br>281<br>282<br>283<br>284<br>285<br>286<br>287<br>``` | ```md-code__content<br>async def stream(self) -> AsyncIterator[VoiceStreamEvent]:<br>    """Stream the events and audio data as they're generated."""<br>    while True:<br>        try:<br>            event = await self._queue.get()<br>        except asyncio.CancelledError:<br>            break<br>        if isinstance(event, VoiceStreamEventError):<br>            self._stored_exception = event.error<br>            logger.error(f"Error processing output: {event.error}")<br>            break<br>        if event is None:<br>            break<br>        yield event<br>        if event.type == "voice_stream_event_lifecycle" and event.event == "session_ended":<br>            break<br>    self._check_errors()<br>    self._cleanup_tasks()<br>    if self._stored_exception:<br>        raise self._stored_exception<br>``` |